
approach: 1

# 1: parallel rxn-enum & div-enum in each rule
# 2: find recent solution, perform iteration (not too much in parallel!)
# 3: rxn-enum -> concat -> div-enum
# rxn: just perform rxn-enum
# icut: just perform icut
# max: just perform maxdist
# div: just perform div-enum

model: toy_models/small4M.json
# path to a cobrapy-compatible model (sbml, matlab or json format)

reaction_weights: toy_models/small4M_weights.csv
# path to a reaction-weight csv file

output_path: cluster_small4M/
# Folder to which the files are written. The folder will be created if not present

parallel_batches: 5
# number of parallel batches to run

enum_iterations: 5
# number of enumeration iterations per batch

rxn_iterations: 2
#ONLY for approach 1 & approach 3: number of reaction-enumeration iterations per batch

starting_solution: false
# an imat solution to be used as a starting point for enumeration, optional input
# set to 'false' when not in use

reaction_list: false
# list of reactions in the model, optional input for reaction-enumeration
# set to 'false' when not in use


full: false
# determines whether or not to use the full-DEXOM implementation.
# This implementation requires much longer runtimes, but takes into account all reactions of the model

cores: 4
# number of cores to assign for each job
memory: 64
# allocated memory per job in gigabytes
time: 00:10:00
